{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaehwachung/Data-Analysis-with-Open-Source/blob/main/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D_13%EA%B0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsg9XBeUxeaC"
      },
      "source": [
        "# 13강 반정형 데이터 분석 : 게시판 글 데이터 활용\n",
        "\n",
        "### 목표\n",
        "\n",
        "방송통신대학교 학생 게시판의 글 제목을 수집하고 분석하여, 반정형 데이터의 수집부터 텍스트 분석까지 전체 과정을 실습\n",
        "\n",
        "### 분석 프로세스 개요\n",
        "\n",
        "1. 데이터 수집\n",
        "  - selenium을 활용한 웹 페이지 접근\n",
        "  - lxml을 이용한 HTML 파싱\n",
        "  - 게시글 제목 추출\n",
        "\n",
        "2. 텍스트 데이터 전처리\n",
        "  - 정규식을 활용한 텍스트 정제\n",
        "  - 형태소 분석을 통한 명사 추출\n",
        "\n",
        "3. 키워드 분석\n",
        "  - 단어 빈도 분석\n",
        "  - 워드 클라우드 생성\n",
        "  - 주요 키워드 추출\n",
        "\n",
        "4. 텍스트 분류 및 시각화\n",
        "  - LLM을 활용한 텍스트 분류\n",
        "  - 분류 결과 시각화\n",
        "  - 인사이트 도출\n",
        "\n",
        "\n",
        "# 주의 : 런타임 GPU 로 설정 필요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGglZIa2Bt0V"
      },
      "outputs": [],
      "source": [
        "# LLM 처리를 위한 VLLM 설치 (오래걸리는 작업이므로 미리 실행!)\n",
        "!pip install vllm\n",
        "# 필요 시 세션 재시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVANXVuyxoEG"
      },
      "outputs": [],
      "source": [
        "# 한글 처리를 위한 matplotlib 설정 (1)\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache –fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trq1ANRexrPL"
      },
      "source": [
        "- 런타임 -> 세션 다시 시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDTgAuhmxqWq"
      },
      "outputs": [],
      "source": [
        "# 한글 처리를 위한 matplotlib 설정 (2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d64GLmjfymL2"
      },
      "source": [
        "# 1. 데이터 수집 및 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6W6viEm1ywgI"
      },
      "source": [
        "## 13-1 웹 스크래핑 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3mh7GL7-xuP"
      },
      "outputs": [],
      "source": [
        "!pip install google-colab-selenium lxml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K05_-Kx0y7ST"
      },
      "source": [
        "## 13-2 웹 스크래핑 함수 정의 및 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPATxfmD--q0"
      },
      "outputs": [],
      "source": [
        "import google_colab_selenium as gs\n",
        "from lxml import html\n",
        "\n",
        "## URL로부터 페이지 내용 가져오기\n",
        "def get_page(driver, url):\n",
        "    # url 페이지로 이동\n",
        "\n",
        "    # 해당 페이지의 html을 page_content로 저장\n",
        "\n",
        "    # page_content를 lxml의 html 객체로 변환하고 tree로 저장\n",
        "\n",
        "    return tree\n",
        "\n",
        "## HTML 트리에서 제목 추출\n",
        "def extract_titles(tree):\n",
        "    ## td-subject를 클래스로 가지는 td 태그 > a태그 > string > text() 을 xpath로 구하고 titles로 저장\n",
        "\n",
        "    return titles\n",
        "\n",
        "## 제목 목록 출력\n",
        "def print_titles(titles):\n",
        "    for title in titles:\n",
        "        print(title)\n",
        "\n",
        "## Chrome 드라이버 초기화\n",
        "driver = gs.Chrome()\n",
        "\n",
        "## 컴퓨터과학과 게시판 첫번째 페이지 제목 데이터 수집\n",
        "board_name = '컴퓨터과학과'\n",
        "board_url = 'https://cs.knou.ac.kr/cs1/4794/subview.do'\n",
        "tree = get_page(driver, board_url)\n",
        "titles = extract_titles(tree)\n",
        "print_titles(titles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ctjR2Gp0Lhc"
      },
      "source": [
        "## 13-3 다중 페이지 데이터 수집 및 데이터프레임 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mliCGdpm_ai2"
      },
      "outputs": [],
      "source": [
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import pandas as pd\n",
        "\n",
        "## 다음 페이지로 이동하고 tree 정보 반환\n",
        "def move_to_next_page(driver):\n",
        "    # _listNext 클래스를 기준으로 엘리먼트 선택\n",
        "\n",
        "    if next_page_link and next_page_link.is_enabled():\n",
        "        # 다음 페이지 버튼 클릭\n",
        "\n",
        "        WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_element_located((By.CLASS_NAME, \"board-table\"))\n",
        "        )\n",
        "        page_content = driver.page_source\n",
        "        tree = html.fromstring(page_content)\n",
        "        return tree\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "## 여러 페이지에서 게시물 제목 가져오기\n",
        "def get_board_titles(url, pages, verbose=False):\n",
        "    driver = gs.Chrome()\n",
        "    board_titles = []\n",
        "    for page in pages:\n",
        "        if verbose:\n",
        "          print(f\"=== 페이지 {page} 처리중입니다. ===\")\n",
        "        if page == 1:\n",
        "            # 13-2 에서 작성한 get_page 함수를 이용하여 현재 페이지 tree 구하기\n",
        "\n",
        "        else:\n",
        "            # 다음 페이지로 이동하고 해당 페이지 tree 구하기\n",
        "\n",
        "        if tree is not None:\n",
        "            titles = extract_titles(tree)\n",
        "            board_titles.extend(titles)\n",
        "            if verbose:\n",
        "              print_titles(titles)\n",
        "    driver.quit()  # Chrome 드라이버 종료\n",
        "    return board_titles\n",
        "\n",
        "## 컴퓨터과학과 게시판 1 페이지 ~ 10 페이지의 제목 데이터 수집\n",
        "board_name = '컴퓨터과학과'\n",
        "board_url = 'https://cs.knou.ac.kr/cs1/4794/subview.do'\n",
        "board_titles = get_board_titles(url=board_url, pages=range(1,11), verbose=True)\n",
        "## 컴퓨터과학과 제목 데이터프레임 생성\n",
        "cs_df = pd.DataFrame(data = {'제목': board_titles})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJk2hGTw0axj"
      },
      "source": [
        "# 2. 텍스트 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNO-W1qT1PMu"
      },
      "source": [
        "## 13-4 정규식을 활용한 텍스트 정제"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LmM7yjY_gCt"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "## 텍스트 정제 함수\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "       # 특수 문자 제거 regex (영어 소문자, 영어 대문자, 숫자, 한글, 공백글자만 허용)\n",
        "\n",
        "       # HTML 태그 제거 regex\n",
        "\n",
        "       # 소문자로 변환 python 함수\n",
        "\n",
        "       return text\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "## 데이터프레임 정제 함수\n",
        "def clean_df(df):\n",
        "  if not df.empty:\n",
        "      df['정제된 제목'] = df['제목'].apply(clean_text)\n",
        "\n",
        "## cs_df에 정제 함수 적용\n",
        "clean_df(cs_df)\n",
        "cs_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWDfZdmV1lq0"
      },
      "source": [
        "## 13-5 형태소 분석기 설치 및 실행 예시"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bAkMpaA7-KA"
      },
      "outputs": [],
      "source": [
        "## Kiwi 형태소 분석기 설치\n",
        "!pip install kiwipiepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBp2vbKh_h9-"
      },
      "outputs": [],
      "source": [
        "from kiwipiepy import Kiwi\n",
        "\n",
        "## 형태소 분석기 초기화 및 사용자 사전 추가\n",
        "kiwi = Kiwi()\n",
        "kiwi.add_user_word('방송대', 'NNP')\n",
        "\n",
        "## 문장 형태소 분석 결과 출력\n",
        "print(kiwi.analyze('안녕하세요 저는 방송대 학생입니다.')[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCxXjvl-2Avs"
      },
      "source": [
        "## 13-6 형태소 분석을 통한 품사 분리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJtGSe0n_jr2"
      },
      "outputs": [],
      "source": [
        "from kiwipiepy import Kiwi\n",
        "\n",
        "## 형태소 분석기 초기화 및 사용자 사전 추가\n",
        "kiwi = Kiwi()\n",
        "kiwi.add_user_word('방송대', 'NNP')\n",
        "kiwi.add_user_word('방통대', 'NNP')\n",
        "\n",
        "## 텍스트 형태소 분석 함수\n",
        "def analyze_morphemes(text):\n",
        "    if isinstance(text, str):\n",
        "       result = kiwi.analyze(text)\n",
        "\n",
        "       morphemes = []\n",
        "       for token in result[0][0]:\n",
        "            ## 형태소(form)와 품사(tag) 정보를 튜플로 morphemes에 추가\n",
        "\n",
        "       return morphemes\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "## 데이터프레임에 형태소 분석 적용 함수\n",
        "def pos_df(df):\n",
        "  if not df.empty:\n",
        "      # `정제된 제목` 칼럼의 값에 analyze_morphemes 함수를 적용하고 결과를 `행태소 분석 결과` 칼럼에 저장\n",
        "\n",
        "\n",
        "## 형태소 분석 적용\n",
        "pos_df(cs_df)\n",
        "cs_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRh5gwXH2io7"
      },
      "source": [
        "## 13-7 명사 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXTePGLH_ldk"
      },
      "outputs": [],
      "source": [
        "## 형태소 분석 결과에서 명사 추출\n",
        "def extract_nouns(morphemes):\n",
        "  # 형태소가 NNG (일반명사), NNP (고유명사) 인 word를 nouns에 저장\n",
        "\n",
        "  return nouns\n",
        "\n",
        "## 데이터프레임에 명사 추출 적용\n",
        "def noun_df(df):\n",
        "  if not df.empty:\n",
        "      df['명사'] = df['형태소 분석 결과'].apply(extract_nouns)\n",
        "\n",
        "## 명사 추출 적용\n",
        "noun_df(cs_df)\n",
        "cs_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1WynjOx21uk"
      },
      "source": [
        "## 13-8 데이터 전처리 통합 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NTCaHG5_nK0"
      },
      "outputs": [],
      "source": [
        "## 데이터프레임 전처리 통합 함수\n",
        "def preprocessing_df(df):\n",
        "  clean_df(df) ## 텍스트 정제 적용\n",
        "  pos_df(df) ## 형태소 분석 적용\n",
        "  noun_df(df) ## 명사 추출 적용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtSkSwjR2_xa"
      },
      "source": [
        "# 3. 키워드 분석"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ2O1bhg3C4l"
      },
      "source": [
        "## 13-9 단어 빈도 계산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1o2UfzE_oiM"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "## 데이터프레임에서 단어 빈도 계산\n",
        "def get_word_count(df):\n",
        "    if not df.empty:\n",
        "        # 모든 명사의 리스트를 구함\n",
        "\n",
        "        # 모든 명사들에 대한 Counter 객체(빈도 정보) 를 반환\n",
        "\n",
        "\n",
        "## cs_df의 단어 빈도 계산\n",
        "word_count = get_word_count(cs_df)\n",
        "print(\"단어 빈도:\")\n",
        "## 상위 30개 단어(most_common)의 빈도 출력\n",
        "for word, freq in word_count.most_common(30):\n",
        "    print(f\"{word}: {freq}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhprrHJY3V6Z"
      },
      "source": [
        "## 13-10 워드클라우드 생성 및 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SygyfSLZ76AX"
      },
      "outputs": [],
      "source": [
        "## WordCloud 라이브러리 설치\n",
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVBFhk19_qfE"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## 단어 빈도를 바탕으로 워드클라우드 생성 및 표시\n",
        "def plot_wordcloud(word_count):\n",
        "    ## 워드 클라우드 생성\n",
        "    wordcloud = WordCloud(\n",
        "        width=800,\n",
        "        height=400,\n",
        "        background_color='white',\n",
        "        colormap='viridis',\n",
        "        font_path='/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' ## 한글 폰트 경로 지정\n",
        "        ).# word_count의 빈도 정보를 이용하여 생성\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear') ## 이미지 표시\n",
        "    plt.axis(\"off\") ## 축 비활성화\n",
        "    plt.show() ## 그래프 표시\n",
        "\n",
        "## cs_df에서 단어 빈도 계산\n",
        "word_count = get_word_count(cs_df)\n",
        "## 워드클라우드 생성 및 표시\n",
        "plot_wordcloud(word_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PvAyYlZ3usb"
      },
      "source": [
        "## 13-11 다른 학과의 워드 클라우드 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyJi1W3X_sJs"
      },
      "outputs": [],
      "source": [
        "board_name = '국어국문학과'\n",
        "board_url = 'https://korean.knou.ac.kr/korean/5323/subview.do'\n",
        "board_titles = get_board_titles(url=board_url, pages=range(1,11), verbose=False)\n",
        "ko_df = pd.DataFrame(data = {'제목': board_titles})\n",
        "preprocessing_df(ko_df)\n",
        "word_count = get_word_count(ko_df)\n",
        "plot_wordcloud(word_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EloJK5-_twx"
      },
      "outputs": [],
      "source": [
        "board_name = '법학과'\n",
        "board_url = 'https://law.knou.ac.kr/law/5176/subview.do'\n",
        "board_titles = get_board_titles(url=board_url, pages=range(1,11), verbose=False)\n",
        "law_df = pd.DataFrame(data = {'제목': board_titles})\n",
        "preprocessing_df(law_df)\n",
        "word_count = get_word_count(law_df)\n",
        "plot_wordcloud(word_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH-1_5QA35p6"
      },
      "source": [
        "# 4. 텍스트 분류 및 시각화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT-GVz0r5GY8"
      },
      "source": [
        "## 13-12 VLLM 라이브러리 설치 및 LLM 모델 로드\n",
        "\n",
        "주의\n",
        "- 런타임 유형 : GPU\n",
        "- 라이브러리 설치 및 모델 다운로드에 수 분(>6분)의 시간이 소요됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLVH4M9R_wC5"
      },
      "outputs": [],
      "source": [
        "from vllm import LLM\n",
        "\n",
        "## LLM 모델 로드 및 설정\n",
        "llm = LLM(\n",
        "    model=\"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\",\n",
        "    tensor_parallel_size=1,\n",
        "    dtype=\"half\",\n",
        "    gpu_memory_utilization=0.6,\n",
        "    max_model_len=32000\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9dIjmw1-n1T"
      },
      "source": [
        "## 13-13 LLM 샘플링 파라미터 설정 및 프롬프트 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WygrPK_V_xl5"
      },
      "outputs": [],
      "source": [
        "from vllm import SamplingParams ## SamplingParams 클래스 임포트\n",
        "\n",
        "## 샘플링 파라미터 설정\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.3, ## 생성 텍스트의 다양성 조절\n",
        "    top_p=1.0, ## top_p 누적 확률 내에서 토큰 샘플링\n",
        "    max_tokens=512, ## 생성될 최대 토큰 수\n",
        "    frequency_penalty=0.5 ## 자주 나타나는 토큰에 대한 패널티\n",
        ")\n",
        "\n",
        "def format_prompt(user_input: str) -> str:\n",
        "    ## 프롬프트 형식화 함수\n",
        "    messages = [\n",
        "        # 시스템 메시지 추가\n",
        "        # 사용자 메시지 추가\n",
        "    ]\n",
        "    return messages\n",
        "\n",
        "## 프롬프트 생성\n",
        "prompt = format_prompt(\"대한민국의 수도는 어디인가요? 수도에 여행하러간다면 어떤 즐길거리가 있을까요?\")\n",
        "\n",
        "## LLM을 사용하여 텍스트 생성\n",
        "# chat 함수를 이용 (프롬프트와 샘플링 파라미터)\n",
        "\n",
        "\n",
        "## 생성된 텍스트 출력\n",
        "print(\"\\n생성된 텍스트:\", outputs[0].outputs[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOuwGZ_r-9HV"
      },
      "source": [
        "## 13-14 LLM 기반 분류 프롬프트 및 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eea5BV77_0Zp"
      },
      "outputs": [],
      "source": [
        "## 분류 프롬프트 형식화 함수\n",
        "def format_classifier_prompt(board_title, title) -> str:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"\"\"주어진 글의 제목을 분류하는 AI 모델입니다.\n",
        "분류 클래스는 학사/전공, 학생활동, 외부정보로 나뉘어집니다.\n",
        "- 학사/전공: 교재, 과제, 시험 등 학업 및 전공 관련 내용\n",
        "- 학생활동: 동아리, 스터디, 모임 등 학생들의 자발적 활동\n",
        "- 외부정보: 취업, 공모전, 행사 등 외부 정보\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": \"\"\"예시)\n",
        "전공명: 컴퓨터학과, 제목: 프로그래밍 과제 질문 -> 학사/전공\n",
        "전공명: 컴퓨터학과, 제목: 알고리즘 스터디 모집 -> 학생활동\n",
        "전공명: 컴퓨터학과, 제목: IT 취업 박람회 -> 외부정보\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": f\"전공명: {board_title}\\n제목: {title}\"}\n",
        "    ]\n",
        "    return messages\n",
        "\n",
        "## 분류 수행 함수\n",
        "def classify(major, title):\n",
        "    prompt = format_classifier_prompt(major, title) ## 분류 프롬프트 생성\n",
        "    outputs = llm.chat([prompt], sampling_params) ## LLM으로 분류 실행\n",
        "    return outputs[0].outputs[0].text ## 분류 결과 텍스트 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNWLOItH_3Sa"
      },
      "outputs": [],
      "source": [
        "classify('컴퓨터학과', '딥러닝 개발 중에 질문 있습니다.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classify('컴퓨터학과', '연극 동아리 회원 모집!! 신규 단원 혜택! AI로 배우는 연극!')"
      ],
      "metadata": {
        "id": "8yho1k1yrA0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMFn08KB_G36"
      },
      "source": [
        "## 13-15 분류 결과 파싱 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TpGbVJd_4yg"
      },
      "outputs": [],
      "source": [
        "def get_class(analysis_result):\n",
        "    ## 분석 결과에서 분류 클래스 추출\n",
        "    classes = ['학사/전공', '학생활동', '외부정보', '기타']\n",
        "    classes_index = [analysis_result.find(cls) for cls in classes]\n",
        "\n",
        "    min_index = float('inf')\n",
        "    min_class = '기타'\n",
        "\n",
        "    for i in range(len(classes)):\n",
        "        current_index = classes_index[i]\n",
        "        if current_index != -1 and current_index < min_index:\n",
        "            min_index = current_index\n",
        "            min_class = classes[i]\n",
        "\n",
        "    return min_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZutwVDJF_6u_"
      },
      "outputs": [],
      "source": [
        "## 컴퓨터과학과 제목 분류 헬퍼 함수 정의\n",
        "def classify_cs(title):\n",
        "  return classify('컴퓨터과학과', title)\n",
        "\n",
        "## '제목' 컬럼에 분류 함수 적용하여 분석 결과 저장\n",
        "cs_df['class_analysis'] = cs_df['제목'].apply(classify_cs)\n",
        "## 분석 결과에서 최종 분류 클래스 추출하여 저장\n",
        "cs_df['class'] = cs_df['class_analysis'].apply(get_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXosbkzW_R4z"
      },
      "source": [
        "## 13-17 분류 결과 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcNZ9FtU_8MY"
      },
      "outputs": [],
      "source": [
        "def plot_class(df):\n",
        "  ## 분류 클래스별 개수 계산 및 순서 재정렬\n",
        "  class_counts = df['class'].value_counts().reindex(['학사/전공', '학생활동', '외부정보'])\n",
        "\n",
        "  plt.figure(figsize=(8, 6)) ## 그래프 크기 설정\n",
        "  plt.pie(class_counts,\n",
        "          labels=class_counts.index,\n",
        "          autopct='%.1f%%', ## 퍼센트 표시 형식\n",
        "          startangle=90, ## 시작 각도 설정\n",
        "          )\n",
        "\n",
        "  plt.title('Class Distribution') ## 그래프 제목 설정\n",
        "  plt.axis('equal') ## 원형 비율 유지\n",
        "  plt.show() ## 그래프 표시\n",
        "\n",
        "plot_class(cs_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx4cTNzQAdFm"
      },
      "source": [
        "## 13-18 다른 학과의 분류 결과 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHvvCO50_9kI"
      },
      "outputs": [],
      "source": [
        "def classify_ko(title):\n",
        "  return classify('국어국문학과', title)\n",
        "\n",
        "ko_df['class_analysis'] = ko_df['제목'].apply(classify_ko)\n",
        "ko_df['class'] = ko_df['class_analysis'].apply(get_class)\n",
        "\n",
        "def classify_law(title):\n",
        "  return classify('법학과', title)\n",
        "\n",
        "law_df['class_analysis'] = law_df['제목'].apply(classify_law)\n",
        "law_df['class'] = law_df['class_analysis'].apply(get_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DZHhHDG_--w"
      },
      "outputs": [],
      "source": [
        "plot_class(ko_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssLCuuP4AALo"
      },
      "outputs": [],
      "source": [
        "plot_class(law_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}