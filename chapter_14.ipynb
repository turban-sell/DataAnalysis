{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaehwachung/Data-Analysis-with-Open-Source/blob/main/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D_14%EA%B0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14강 비정형 데이터 분석 : 패션 사진 데이터 활용\n",
        "\n",
        "### 목표\n",
        "\n",
        "- 비정형 데이터를 인공지능 모델로 분석하여 실무에서 활용 가능한 보고서 형태로 가공\n",
        "\n",
        "- 패션 트렌드라는 구체적인 주제를 통해, 비정형 데이터 분석의 실질적인 활용 방안을 경험하고자 함\n",
        "\n",
        "\n",
        "### 분석 프로세스 개요\n",
        "\n",
        "1. 데이터 수집\n",
        "  - requests를 이용한 RSS 데이터 수집\n",
        "  - lxml을 이용한 XML 파싱\n",
        "  - 이미지 데이터 추출\n",
        "2. VLM을 이용한 이미지 분석\n",
        "  - 프롬프트를 이용한 이미지 필터링\n",
        "  - 프롬프트를 이용한 스타일 분석\n",
        "3. LLM을 이용한 키워드 분석 및 보고서 작성\n",
        "  - 텍스트 전처리\n",
        "  - 색상 및 스타일 키워드 추출\n",
        "  - 워드 클라우드 분석\n",
        "  - 보고서 작성\n",
        "\n",
        "# 주의 : 런타임 GPU 로 설정 필요"
      ],
      "metadata": {
        "id": "xFHAUHwUwqEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4bit VLM 처리를 위한 bitsandbytes 설치\n",
        "# LLM 처리를 위한 VLLM 설치 (오래걸리는 작업(>5분)이므로 미리 실행!)\n",
        "!pip install bitsandbytes==0.45.3 vllm==0.7.3 transformers==4.48.2\n",
        "# 필요 시 세션 재시작"
      ],
      "metadata": {
        "id": "oRFE0WufwtWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글 처리를 위한 matplotlib 설정 (1)\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache –fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "id": "2PyUVMjnwv4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 런타임 -> 세션 다시 시작"
      ],
      "metadata": {
        "id": "xjT6NMJ_wxoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글 처리를 위한 matplotlib 설정 (2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ],
      "metadata": {
        "id": "1Q-jeRwcwzly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터 수집 및 전처리"
      ],
      "metadata": {
        "id": "Evptw6-lw2j-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-1 RSS 피드에서 이미지 URL 추출"
      ],
      "metadata": {
        "id": "GyE957VBw3Nt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjrPWcd1AFKx"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from lxml import etree\n",
        "from lxml.html import fromstring\n",
        "import pandas as pd\n",
        "\n",
        "def extract_unique_images(rss_url):\n",
        "    ## 주어진 RSS 피드 URL에서 고유한 이미지 URL들을 추출하는 함수 정의\n",
        "    try:\n",
        "        ## requests 라이브러리를 사용하여 RSS 피드 URL로부터 내용을 가져옴\n",
        "        response = requests.get(rss_url)\n",
        "        ## 가져온 XML 응답 내용을 lxml의 etree.fromstring으로 파싱하여 XML 트리 root를 생성\n",
        "\n",
        "        image_urls = set()\n",
        "\n",
        "        ## XML 트리에서 모든 'item' 태그를 XPath를 사용하여 순회\n",
        "        for item in root.xpath('//item'):\n",
        "            description = item.find('description')\n",
        "            if description is not None and description.text:\n",
        "                ## description의 텍스트 내용을 lxml.html.fromstring으로 파싱하여 HTML 트리를 생성\n",
        "\n",
        "                ## HTML 트리에서 첫 번째 <img> 태그의 'src' 속성 값을 XPath를 사용하여 추출\n",
        "\n",
        "                if img_url:\n",
        "                    image_urls.add(img_url)\n",
        "\n",
        "        return list(image_urls)\n",
        "\n",
        "    except Exception as e:\n",
        "        ## 오류 발생 시 오류 메시지를 출력하고 빈 리스트를 반환\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        return []\n",
        "\n",
        "rss_url = \"https://glltn.com/feed/\"\n",
        "## extract_unique_images 함수를 호출하여 고유한 이미지 URL들을 추출\n",
        "unique_images = extract_unique_images(rss_url)\n",
        "\n",
        "## 추출된 이미지 URL 리스트를 사용하여 'image'라는 열을 가진 pandas DataFrame을 생성\n",
        "df = pd.DataFrame(unique_images, columns=[\"image\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-2 수집 데이터 확인"
      ],
      "metadata": {
        "id": "XT6FFqgn42yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "def path_to_image_html(path):\n",
        "    ## 이미지 경로를 HTML img 태그로 변환하는 함수\n",
        "    return f'<img src=\"{path}\" width=\"300\" />'\n",
        "\n",
        "## DataFrame의 스타일을 설정하여 이미지 너비를 300px로 지정\n",
        "df.style.set_table_styles([{'selector': 'img', 'props': 'width: 300px;'}])\n",
        "\n",
        "## DataFrame을 HTML로 변환하여 출력. 이미지 열은 path_to_image_html 함수로 포맷팅\n",
        "display(HTML(df.to_html(escape=False, formatters=dict(**{'image': path_to_image_html}))))"
      ],
      "metadata": {
        "id": "DVMvyxJOAOo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. VLM을 이용한 이미지 분석"
      ],
      "metadata": {
        "id": "X8tIpX9A3oMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-3 VLM 모델 로드"
      ],
      "metadata": {
        "id": "wKQ3p2-alzLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "## 'openbmb/MiniCPM-V-2_6-int4' 모델을 사전 훈련된 가중치와 함께 로드\n",
        "## trust_remote_code=True는 허브에서 사용자 정의 코드를 실행할 수 있도록 허용\n",
        "model = AutoModel.from_pretrained('openbmb/MiniCPM-V-2_6-int4', trust_remote_code=True)\n",
        "## 로드된 모델에 해당하는 토크나이저를 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-2_6-int4', trust_remote_code=True)\n",
        "## 모델을 평가 모드로 설정 (드롭아웃 등 훈련 시에만 필요한 기능 비활성화)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "c1IXBK01ASWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://farm3.staticflickr.com/2677/4434956914_6e95a22940_z.jpg)"
      ],
      "metadata": {
        "id": "xrr3p8fslk4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-4 이미지 질문 응답 예시"
      ],
      "metadata": {
        "id": "58PxIp8SmUl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "## 재현성을 위해 시드(seed)를 42로 설정\n",
        "set_seed(42)\n",
        "## 예시 이미지 URL 정의\n",
        "image_url = 'https://farm3.staticflickr.com/2677/4434956914_6e95a22940_z.jpg'\n",
        "## requests로 이미지 다운로드 후 PIL Image 객체로 열고 RGB 형식으로 변환\n",
        "image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
        "## 이미지에 대한 질문 정의\n",
        "question = 'how many cats in the photo?'\n",
        "## 모델 입력 형식에 맞춰 메시지 구성 (이미지와 질문 포함)\n",
        "msgs = [{'role': 'user', 'content': [image, question]}]\n",
        "## 모델의 chat 함수를 호출하여 이미지와 질문에 대한 응답 생성\n",
        "result = model.chat(image=None, msgs=msgs, tokenizer=tokenizer)\n",
        "## 모델의 응답 출력\n",
        "print(result)"
      ],
      "metadata": {
        "id": "OLk-R6PYATVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "## 이미지에 대한 질문을 업데이트. 책 표지의 고양이도 포함하도록 요청\n",
        "question = 'how many cats in the photo? including the books cover.'\n",
        "## 모델 입력 형식에 맞춰 메시지 구성 (이전에 로드된 이미지와 업데이트된 질문 포함)\n",
        "msgs = [{'role': 'user', 'content': [image, question]}]\n",
        "## 모델의 chat 함수를 호출하여 업데이트된 질문에 대한 응답 생성\n",
        "result = model.chat(image=None, msgs=msgs, tokenizer=tokenizer)\n",
        "## 모델의 응답 출력\n",
        "print(result)"
      ],
      "metadata": {
        "id": "B1KelJIrAU2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "## 이미지에 대한 질문을 'describe the photo'로 설정하여 이미지 내용을 설명하도록 요청\n",
        "question = 'describe the photo'\n",
        "## 모델 입력 형식에 맞춰 메시지 구성 (이전에 로드된 이미지와 설명 요청 질문 포함)\n",
        "msgs = [{'role': 'user', 'content': [image, question]}]\n",
        "## 모델의 chat 함수를 호출하여 이미지에 대한 설명을 생성\n",
        "result = model.chat(image=None, msgs=msgs, tokenizer=tokenizer)\n",
        "## 모델의 응답 (이미지 설명) 출력\n",
        "print(result)"
      ],
      "metadata": {
        "id": "UCd9smsCAWH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-5 의류 이미지 여부 판단"
      ],
      "metadata": {
        "id": "Hyv4G27NnxxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_picture_of_clothing(image_url):\n",
        "    ## 이미지 URL이 의류 사진인지 판단하는 함수\n",
        "    # 의류가 포함된 사진인지 확인하는 질문 작성 (영어로)\n",
        "    question = ''\n",
        "    image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
        "    msgs = [{'role': 'user', 'content': [image, question]}]\n",
        "    result = model.chat(image=None, msgs=msgs, tokenizer=tokenizer, temperature=0.1)\n",
        "    print(result)\n",
        "    ## 응답에 'yes'가 포함되어 있는지 확인하여 True/False 반환\n",
        "    return 'yes' in result.lower()\n",
        "\n",
        "## DataFrame의 'image' 열에 함수를 적용하여 'is_clothing' 열에 결과 저장\n",
        "df['is_clothing'] = df['image'].apply(is_picture_of_clothing)"
      ],
      "metadata": {
        "id": "KnJ0trHgAXTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-6 의류 판단 결과 시각화"
      ],
      "metadata": {
        "id": "l4l7QsLaoCoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(df.to_html(escape=False, formatters=dict(**{'image': path_to_image_html}))))"
      ],
      "metadata": {
        "id": "rOtwke1pAd8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-7 의류 이미지 필터링"
      ],
      "metadata": {
        "id": "0aSaNQ7eoUWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 'is_clothing' 열의 값이 True인 행들만 필터링하여 DataFrame을 업데이트\n"
      ],
      "metadata": {
        "id": "X3prbhccAfdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-8 의류 스타일 분석"
      ],
      "metadata": {
        "id": "UMo5LkOzoaEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def describe_style(image_url):\n",
        "    ## 주어진 이미지 URL의 의류 스타일을 분석하는 함수\n",
        "    question = ''\n",
        "    image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
        "    msgs = [{'role': 'user', 'content': [image, question]}]\n",
        "    ## 모델의 chat 함수를 호출하여 이미지에 대한 스타일 분석 응답 생성\n",
        "    result = model.chat(image=None, msgs=msgs, tokenizer=tokenizer)\n",
        "    return result\n",
        "\n",
        "## 필터링된 DataFrame의 'image' 열에 describe_style 함수를 적용\n",
        "## 결과는 'style'이라는 새로운 열에 저장\n",
        "df['style'] = df['image'].apply(describe_style)"
      ],
      "metadata": {
        "id": "FxgObQ1ZAgVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(df.to_html(escape=False, formatters=dict(**{'image': path_to_image_html}))))"
      ],
      "metadata": {
        "id": "i-znn3Z0qjJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. LLM을 이용한 키워드 분석 및 보고서 작성"
      ],
      "metadata": {
        "id": "0z6BhTZeopo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-9 언어 모델(LLM) 로드"
      ],
      "metadata": {
        "id": "ebRE0K15oqr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "## vLLM 라이브러리를 사용하여 'LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct' 모델을 로드\n",
        "## gpu_memory_utilization은 GPU 메모리 사용 비율을 0.5로 설정\n",
        "## max_model_len은 모델이 처리할 수 있는 최대 토큰 길이를 10000으로 설정\n"
      ],
      "metadata": {
        "id": "hiQAZ-csAiI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-10 색상 정보 추출"
      ],
      "metadata": {
        "id": "Sj470n8wo86w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import SamplingParams ## SamplingParams 임포트가 필요\n",
        "\n",
        "def extract_color(style):\n",
        "  ## 주어진 스타일 설명 텍스트에서 색상을 한글로 추출하는 함수\n",
        "  prompt = [\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"\n",
        "      },\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": f\"\" # vlm이 작성한 글에서 색상 정보 추출, 한글로 번역하면서\n",
        "      }\n",
        "  ]\n",
        "  ## 샘플링 파라미터 설정 (온도, top_p, 최대 토큰 수)\n",
        "  sampling_params = SamplingParams(temperature=0.2, top_p=0.95, max_tokens=1024)\n",
        "  ## LLM 모델을 사용하여 프롬프트에 대한 응답 생성\n",
        "  result = llm.chat(prompt, sampling_params)[0].outputs[0].text\n",
        "  print(result)\n",
        "  return result\n",
        "\n",
        "## DataFrame의 'style' 열에 extract_color 함수를 적용\n",
        "## 결과는 'color'라는 새로운 열에 저장\n",
        "df['color'] = df['style'].apply(extract_color)"
      ],
      "metadata": {
        "id": "ci7oHspgAjuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-11 스타일 키워드 추출"
      ],
      "metadata": {
        "id": "hdHnIoYapBPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import SamplingParams ## SamplingParams 임포트가 필요\n",
        "\n",
        "def extract_color(style):\n",
        "  ## 주어진 스타일 설명 텍스트에서 스타일 키워드를 한글로 추출하는 함수\n",
        "  prompt = [\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"\n",
        "      },\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": f\"\" # vlm이 작성한 글에서 스타일 키워드 추출, 한글로 번역하면서\n",
        "      }\n",
        "  ]\n",
        "  ## 샘플링 파라미터 설정 (온도, top_p, 최대 토큰 수)\n",
        "  sampling_params = SamplingParams(temperature=0.2, top_p=0.95, max_tokens=1024)\n",
        "  ## LLM 모델을 사용하여 프롬프트에 대한 응답 생성\n",
        "  result = llm.chat(prompt, sampling_params)[0].outputs[0].text\n",
        "  print(result)\n",
        "  return result\n",
        "\n",
        "## DataFrame의 'style' 열에 extract_color 함수를 적용 (함수 이름은 이전과 동일하지만 기능 변경)\n",
        "## 결과는 'keyword'라는 새로운 열에 저장\n",
        "df['keyword'] = df['style'].apply(extract_color)"
      ],
      "metadata": {
        "id": "9CGzC0QlAlNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(df.to_html(escape=False, formatters=dict(**{'image': path_to_image_html}))))"
      ],
      "metadata": {
        "id": "nxI64xM-qpRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-12 텍스트 데이터 정제"
      ],
      "metadata": {
        "id": "sLXLdNUhpK8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    ## 텍스트에서 특수 문자 및 HTML 태그를 제거하고 소문자로 변환하는 함수\n",
        "    if isinstance(text, str):\n",
        "       ## 영문, 숫자, 한글, 공백을 제외한 모든 문자 제거\n",
        "       text = re.sub(r'[^a-zA-Z0-9가-힣\\s]', '', text)\n",
        "       ## HTML 태그 제거\n",
        "       text = re.sub(r'<[^>]*>', '', text)\n",
        "       ## 텍스트를 소문자로 변환\n",
        "       text = text.lower()\n",
        "       return text\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "## 'color' 열의 텍스트 데이터 정제\n",
        "df['color'] = df['color'].apply(clean_text)\n",
        "## 'keyword' 열의 텍스트 데이터 정제\n",
        "df['keyword'] = df['keyword'].apply(clean_text)"
      ],
      "metadata": {
        "id": "nAhvdWHVAm0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-13 워드 클라우드 생성 및 시각화"
      ],
      "metadata": {
        "id": "CNg6DakapO_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_word_count(df):\n",
        "    ## DataFrame의 'color'와 'keyword' 열에서 단어 빈도를 계산하는 함수\n",
        "    if not df.empty:\n",
        "        ## 'color' 열의 모든 단어를 리스트로 합침\n",
        "        all_nouns = df['color'].apply(str.split).sum()\n",
        "        ## 'keyword' 열의 모든 단어를 추가\n",
        "        all_nouns += df['keyword'].apply(str.split).sum()\n",
        "        ## '색상' 단어를 제외한 모든 단어를 필터링\n",
        "        all_nouns = [word for word in all_nouns if word not in ['색상']]\n",
        "        ## 단어 빈도를 Counter 객체로 반환\n",
        "        return Counter(all_nouns)\n",
        "    return Counter() ## DataFrame이 비어있으면 빈 Counter 반환\n",
        "\n",
        "def create_wordcloud(word_count):\n",
        "    ## 단어 빈도수를 기반으로 워드 클라우드를 생성하고 시각화하는 함수\n",
        "    if not word_count: ## 단어 빈도가 없으면 워드클라우드 생성하지 않음\n",
        "        print(\"No words to generate word cloud.\")\n",
        "        return\n",
        "\n",
        "    wordcloud = WordCloud(\n",
        "        width=800,\n",
        "        height=400,\n",
        "        background_color='white',\n",
        "        colormap='viridis',\n",
        "        font_path='/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' ## 한글 폰트 경로 지정\n",
        "        ).generate_from_frequencies(word_count)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\") ## 축 표시 제거\n",
        "    plt.show() ## 워드 클라우드 출력\n",
        "\n",
        "## DataFrame에서 단어 빈도 계산\n",
        "word_count = get_word_count(df)\n",
        "## 계산된 단어 빈도로 워드 클라우드 생성 및 시각화\n",
        "create_wordcloud(word_count)"
      ],
      "metadata": {
        "id": "newpDQHoAoGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-14 트렌드 분석 보고서 생성 프롬프트 구성 및 실행"
      ],
      "metadata": {
        "id": "eDO_o8uop2M_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-15 분석 보고서 시각화"
      ],
      "metadata": {
        "id": "m304vCZMp7ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import SamplingParams ## SamplingParams 임포트가 필요\n",
        "\n",
        "## 시스템 메시지로 시작하는 프롬프트 리스트 초기화\n",
        "prompt = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"\n",
        "    }\n",
        "]\n",
        "## DataFrame의 각 행을 순회하며 '스타일 노트'와 '이미지 URL'을 사용자 메시지로 추가\n",
        "for row in df.itertuples():\n",
        "  prompt.append({\"role\": \"user\", \"content\": f\"\"})\n",
        "## 마지막으로, 종합적인 트렌드 분석 보고서 작성을 요청하는 사용자 메시지 추가\n",
        "## 보고서 제목, 내용의 전문성, 마크다운 형식, 예시 이미지 포함을 지시\n",
        "prompt.append({\"role\": \"user\", \"content\": \"\"})\n",
        "\n",
        "## 샘플링 파라미터 설정 (온도, top_p, 최대 토큰 수)\n",
        "sampling_params = SamplingParams(temperature=0.2, top_p=0.95, max_tokens=4096)\n",
        "## LLM 모델을 사용하여 구성된 프롬프트에 대한 응답 생성\n",
        "result = llm.chat(prompt, sampling_params)[0].outputs[0].text"
      ],
      "metadata": {
        "id": "x6LZ3FCtApst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "## LLM으로부터 생성된 결과(Markdown 형식의 보고서)를 Jupyter 환경에 표시\n",
        "display(Markdown(result))"
      ],
      "metadata": {
        "id": "7C7KDpS6Aq7w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}